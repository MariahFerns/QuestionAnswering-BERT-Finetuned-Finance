# QuestionAnswering-BERT-Finetuned-Finance

‚óè	The objective is to develop a model that can not only answer questions based on documents but also enhance the content comprehension or generate new content that supports the answers. The model must be trained to expand on answers with additional context generated from its understanding. This can be particularly useful in educational tools or support systems where deeper understanding and context are required.<br>
<br> ‚óè	This can be achieved using public datasets like the SQuAD (Stanford Question Answering Dataset), which provides a robust foundation for training question answering systems and can be augmented with generative tasks.<br>
<br> ‚óè	As a first step, we have fine tuned BERT on SQuAD which is further finetuned on finance data to answer questions posed by senior leadership.


## [Open model in Hugging Face](https://huggingface.co/Mariah64/distilbert-base-uncased-finetuned-squad-v2) ü§ó
